---
title:          "CORE-Net: A cross-modal orthogonal representation enhancement network for low-altitude multispectral object detection"
date:           2025-12-29 00:00:00 +0800
selected:       False
# pub:            "PLOS ONE"
# pub_pre:        "Submitted to "
pub_post:       'Accepted by PLOS ONE'
# pub_last:       '<span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
# pub_date:       "2025"
# semantic_scholar_id: a8ff80e9762384cf55e05e65610458c0a05fd41a  # use this to retrieve citation count
abstract: >-
  Proposed <strong>CORE-Net</strong>, a efficient dual-branch architecture for multispectral (RGB-IR) object detection that circumvents the heavy computational overhead of traditional cross-modal fusion paradigms. This framework demonstrates superior accuracy and robust performance in low-illumination environments, rendering it well-suited for deployment on resource-constrained edge devices.
# abstract: >-
#   Photo by Pineapple Supply Co. on Unsplash. Please put a tldr (too-long-didnt-read, 1~2 sentences) of your publication here. It is not recommended to put the actual abstract here because it is usually too long to fit in. $\LaTeX$ is supported. $a=b+c$.
cover:          /assets/images/covers/CORE-Net.png
authors:
  - <b>Daoze Tang*</b>
  - Shuyun Tang*
  - Dequan Zheng#
links:
  Paper: https://doi.org/10.1371/journal.pone.0340499
  Code: https://github.com/DaozeTang/CORE-Net
---
